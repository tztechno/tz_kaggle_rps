{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-tablet",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile submission.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "from random import randrange\n",
    "import collections\n",
    "\n",
    "\n",
    "class agent():\n",
    "    def initial_step(self):\n",
    "        return np.random.randint(3)\n",
    "    \n",
    "    def history_step(self, history):\n",
    "        return np.random.randint(3)\n",
    "    \n",
    "    def step(self, history):\n",
    "        if len(history) == 0:\n",
    "            return int(self.initial_step())\n",
    "        else:\n",
    "            return int(self.history_step(history))\n",
    "\n",
    "         \n",
    "############## additional agents  ##############\n",
    "class rps(agent):\n",
    "    def __init__(self, shift=0):\n",
    "        self.shift = shift\n",
    "    \n",
    "    def rps(self, history):\n",
    "        return self.shift % 3\n",
    "\n",
    "      \n",
    "############## origial agents added ##############\n",
    "class j8(agent):\n",
    "\n",
    "    def my_agent_j8(self, observation, configuration):\n",
    "\n",
    "        global opp_history, T, P\n",
    "        opp_history=[]    \n",
    "        T = np.ones((3, 3, 3, 3, 3, 3, 3, 3, 3))\n",
    "        P = np.zeros((3, 3))    \n",
    "        a1, a2 = None, None\n",
    "\n",
    "        if observation['step'] == 0 :\n",
    "            next_hand = np.random.choice( 3 )   \n",
    "            return next_hand   \n",
    "\n",
    "        elif observation['step'] < 10 :\n",
    "            opp_history.append(observation[\"lastOpponentAction\"])   \n",
    "            next_hand = np.random.choice( 3 )   \n",
    "            return next_hand  \n",
    "\n",
    "        else:\n",
    "            opp_history.append(observation[\"lastOpponentAction\"])   \n",
    "\n",
    "            ai1 = opp_history[-1]\n",
    "            ai2 = opp_history[-2]\n",
    "            ai3 = opp_history[-3]\n",
    "            ai4 = opp_history[-4] \n",
    "            ai5 = opp_history[-5] \n",
    "            ai6 = opp_history[-6]  \n",
    "            ai7 = opp_history[-7]  \n",
    "            ai8 = opp_history[-8] \n",
    "            ai9 = opp_history[-9] \n",
    "\n",
    "            T[ai9,ai8,ai7,ai6,ai5,ai4,ai3,ai2,ai1] += 1\n",
    "\n",
    "            a1 = opp_history[-1]\n",
    "            a2 = opp_history[-2]\n",
    "            a3 = opp_history[-3]\n",
    "            a4 = opp_history[-4]  \n",
    "            a5 = opp_history[-5]         \n",
    "            a6 = opp_history[-6]  \n",
    "            a7 = opp_history[-7] \n",
    "            a8 = opp_history[-8] \n",
    "\n",
    "            T1 = T[a8,a7,a6,a5,a4,a3,a2]\n",
    "\n",
    "            P = np.divide(T1, np.maximum(1, T1.sum(axis=1)).reshape(-1, 1))   \n",
    "            next_hand = (np.random.choice(3, p=P[a1,:]) +1) %3    \n",
    "\n",
    "            return next_hand\n",
    "\n",
    "        \n",
    "############## origial agents added ##############\n",
    "class hx(agent):\n",
    "    def __init__(self, shift=0):\n",
    "        self.shift = shift\n",
    "        \n",
    "    def my_agent_hx(self, observation, configuration):\n",
    "        global opp_history\n",
    "        opp_history=[]\n",
    "\n",
    "        if observation['step'] == 0  :\n",
    "            return np.random.choice( 3 )   \n",
    "\n",
    "        elif observation['step'] < self.shift+1 :\n",
    "            opp_history.append(observation[\"lastOpponentAction\"])   \n",
    "            c = collections.Counter(opp_history)\n",
    "            n = c[0] + c[1] + c[2]\n",
    "            max0 = max(c[0],c[1],c[2])\n",
    "            min0 = max(c[0],c[1],c[2])\n",
    "\n",
    "            if max0 == c[0] and min0 == c[1]:\n",
    "                next_hand = np.random.choice( 3, p=[c[2]/(2*n),c[0]/n+c[1]/n,c[2]/(2*n)] )   \n",
    "            elif max0 == c[0] and min0 == c[2]:\n",
    "                next_hand = np.random.choice( 3, p=[c[1]/(2*n),c[0]/n+c[2]/n,c[1]/(2*n)] )           \n",
    "            elif max0 == c[1] and min0 == c[0]:\n",
    "                next_hand = np.random.choice( 3, p=[c[2]/(2*n),c[2]/(2*n),c[1]/n+c[0]/n] )          \n",
    "            elif max0 == c[1] and min0 == c[2]:\n",
    "                next_hand = np.random.choice( 3, p=[c[0]/(2*n),c[0]/(2*n),c[1]/n+c[2]/n] )         \n",
    "            elif max0 == c[2] and min0 == c[1]:\n",
    "                next_hand = np.random.choice( 3, p=[c[2]/n+c[1]/n,c[0]/(2*n),c[0]/(2*n)] )         \n",
    "            elif max0 == c[2] and min0 == c[0]:\n",
    "                next_hand = np.random.choice( 3, p=[c[2]/n+c[0]/n,c[1]/(2*n),c[1]/(2*n)] ) \n",
    "            else:\n",
    "                next_hand = np.random.choice( 3 )             \n",
    "\n",
    "            return next_hand     \n",
    "\n",
    "        else:\n",
    "            opp_history.append(observation[\"lastOpponentAction\"])   \n",
    "            c = collections.Counter(opp_history[-self.shift:])\n",
    "            n = c[0] + c[1] + c[2]\n",
    "            max0 = max(c[0],c[1],c[2])\n",
    "            min0 = max(c[0],c[1],c[2])\n",
    "\n",
    "            if max0 == c[0] and min0 == c[1]:\n",
    "                next_hand = np.random.choice( 3, p=[c[2]/(2*n),c[0]/n+c[1]/n,c[2]/(2*n)] )   \n",
    "            elif max0 == c[0] and min0 == c[2]:\n",
    "                next_hand = np.random.choice( 3, p=[c[1]/(2*n),c[0]/n+c[2]/n,c[1]/(2*n)] )           \n",
    "            elif max0 == c[1] and min0 == c[0]:\n",
    "                next_hand = np.random.choice( 3, p=[c[2]/(2*n),c[2]/(2*n),c[1]/n+c[0]/n] )          \n",
    "            elif max0 == c[1] and min0 == c[2]:\n",
    "                next_hand = np.random.choice( 3, p=[c[0]/(2*n),c[0]/(2*n),c[1]/n+c[2]/n] )         \n",
    "            elif max0 == c[2] and min0 == c[1]:\n",
    "                next_hand = np.random.choice( 3, p=[c[2]/n+c[1]/n,c[0]/(2*n),c[0]/(2*n)] )         \n",
    "            elif max0 == c[2] and min0 == c[0]:\n",
    "                next_hand = np.random.choice( 3, p=[c[2]/n+c[0]/n,c[1]/(2*n),c[1]/(2*n)] ) \n",
    "            else:\n",
    "                next_hand = np.random.choice( 3 )             \n",
    "\n",
    "            return next_hand \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "class mirror_shift(agent):\n",
    "    def __init__(self, shift=0):\n",
    "        self.shift = shift\n",
    "    \n",
    "    def history_step(self, history):\n",
    "        return (history[-1]['competitorStep'] + self.shift) % 3\n",
    "    \n",
    "\n",
    "class self_shift(agent):\n",
    "    def __init__(self, shift=0):\n",
    "        self.shift = shift\n",
    "    \n",
    "    def history_step(self, history):\n",
    "        return (history[-1]['step'] + self.shift) % 3    \n",
    "\n",
    "\n",
    "class popular_beater(agent):\n",
    "    def history_step(self, history):\n",
    "        counts = np.bincount([x['competitorStep'] for x in history])\n",
    "        return (int(np.argmax(counts)) + 1) % 3\n",
    "\n",
    "    \n",
    "class anti_popular_beater(agent):\n",
    "    def history_step(self, history):\n",
    "        counts = np.bincount([x['step'] for x in history])\n",
    "        return (int(np.argmax(counts)) + 2) % 3\n",
    "    \n",
    "    \n",
    "class transition_matrix(agent):\n",
    "    def __init__(self, deterministic = False, counter_strategy = False, init_value = 0.1, decay = 1):\n",
    "        self.deterministic = deterministic\n",
    "        self.counter_strategy = counter_strategy\n",
    "        if counter_strategy:\n",
    "            self.step_type = 'step' \n",
    "        else:\n",
    "            self.step_type = 'competitorStep'\n",
    "        self.init_value = init_value\n",
    "        self.decay = decay\n",
    "        \n",
    "    def history_step(self, history):\n",
    "        matrix = np.zeros((3,3)) + self.init_value\n",
    "        for i in range(len(history) - 1):\n",
    "            matrix = (matrix - self.init_value) / self.decay + self.init_value\n",
    "            matrix[int(history[i][self.step_type]), int(history[i+1][self.step_type])] += 1\n",
    "\n",
    "        if  self.deterministic:\n",
    "            step = np.argmax(matrix[int(history[-1][self.step_type])])\n",
    "        else:\n",
    "            step = np.random.choice([0,1,2], p = matrix[int(history[-1][self.step_type])]/matrix[int(history[-1][self.step_type])].sum())\n",
    "        \n",
    "        if self.counter_strategy:\n",
    "            return (step + 2) % 3 \n",
    "        else:\n",
    "            return (step + 1) % 3\n",
    "    \n",
    "\n",
    "class transition_tensor(agent):\n",
    "    \n",
    "    def __init__(self, deterministic = False, counter_strategy = False, init_value = 0.1, decay = 1):\n",
    "        self.deterministic = deterministic\n",
    "        self.counter_strategy = counter_strategy\n",
    "        if counter_strategy:\n",
    "            self.step_type1 = 'step' \n",
    "            self.step_type2 = 'competitorStep'\n",
    "        else:\n",
    "            self.step_type2 = 'step' \n",
    "            self.step_type1 = 'competitorStep'\n",
    "        self.init_value = init_value\n",
    "        self.decay = decay\n",
    "        \n",
    "    def history_step(self, history):\n",
    "        matrix = np.zeros((3,3,3)) + 0.1\n",
    "        for i in range(len(history) - 1):\n",
    "            matrix = (matrix - self.init_value) / self.decay + self.init_value\n",
    "            matrix[int(history[i][self.step_type1]), int(history[i][self.step_type2]), int(history[i+1][self.step_type1])] += 1\n",
    "\n",
    "        if  self.deterministic:\n",
    "            step = np.argmax(matrix[int(history[-1][self.step_type1]), int(history[-1][self.step_type2])])\n",
    "        else:\n",
    "            step = np.random.choice([0,1,2], p = matrix[int(history[-1][self.step_type1]), int(history[-1][self.step_type2])]/matrix[int(history[-1][self.step_type1]), int(history[-1][self.step_type2])].sum())\n",
    "        \n",
    "        if self.counter_strategy:\n",
    "            return (step + 2) % 3 \n",
    "        else:\n",
    "            return (step + 1) % 3\n",
    "\n",
    "\n",
    "class pattern_matching(agent):\n",
    "    def __init__(self, steps = 3, deterministic = False, counter_strategy = False, init_value = 0.1, decay = 1):\n",
    "        self.deterministic = deterministic\n",
    "        self.counter_strategy = counter_strategy\n",
    "        if counter_strategy:\n",
    "            self.step_type = 'step' \n",
    "        else:\n",
    "            self.step_type = 'competitorStep'\n",
    "        self.init_value = init_value\n",
    "        self.decay = decay\n",
    "        self.steps = steps\n",
    "        \n",
    "    def history_step(self, history):\n",
    "        if len(history) < self.steps + 1:\n",
    "            return self.initial_step()\n",
    "        \n",
    "        next_step_count = np.zeros(3) + self.init_value\n",
    "        pattern = [history[i][self.step_type] for i in range(- self.steps, 0)]\n",
    "        \n",
    "        for i in range(len(history) - self.steps):\n",
    "            next_step_count = (next_step_count - self.init_value)/self.decay + self.init_value\n",
    "            current_pattern = [history[j][self.step_type] for j in range(i, i + self.steps)]\n",
    "            if np.sum([pattern[j] == current_pattern[j] for j in range(self.steps)]) == self.steps:\n",
    "                next_step_count[history[i + self.steps][self.step_type]] += 1\n",
    "        \n",
    "        if next_step_count.max() == self.init_value:\n",
    "            return self.initial_step()\n",
    "        \n",
    "        if  self.deterministic:\n",
    "            step = np.argmax(next_step_count)\n",
    "        else:\n",
    "            step = np.random.choice([0,1,2], p = next_step_count/next_step_count.sum())\n",
    "        \n",
    "        if self.counter_strategy:\n",
    "            return (step + 2) % 3 \n",
    "        else:\n",
    "            return (step + 1) % 3\n",
    "\n",
    "        \n",
    "agents = {\n",
    "       \n",
    "# origial agents added\n",
    "    'j8': j8(),        \n",
    "    'hx200': hx(200),   \n",
    "    'hx250': hx(250),\n",
    "\n",
    "# additional agents    \n",
    "    'rps_0': rps(0),\n",
    "    'rps_1': rps(1),\n",
    "    'rps_2': rps(2),\n",
    "        \n",
    "    'mirror_0': mirror_shift(0),\n",
    "    'mirror_1': mirror_shift(1),  \n",
    "    'mirror_2': mirror_shift(2),\n",
    "    \n",
    "    'self_0': self_shift(0),\n",
    "    'self_1': self_shift(1),  \n",
    "    'self_2': self_shift(2),\n",
    "    \n",
    "    'popular_beater': popular_beater(),\n",
    "    'anti_popular_beater': anti_popular_beater(),\n",
    "    'random_transitison_matrix': transition_matrix(False, False),\n",
    "    'determenistic_transitison_matrix': transition_matrix(True, False),\n",
    "    'random_self_trans_matrix': transition_matrix(False, True),\n",
    "    'determenistic_self_trans_matrix': transition_matrix(True, True),\n",
    "    'random_transitison_tensor': transition_tensor(False, False),\n",
    "    'determenistic_transitison_tensor': transition_tensor(True, False),\n",
    "    'random_self_trans_tensor': transition_tensor(False, True),\n",
    "    'determenistic_self_trans_tensor': transition_tensor(True, True),\n",
    "    \n",
    "    'random_transitison_matrix_decay': transition_matrix(False, False, decay = 1.05),\n",
    "    'random_self_trans_matrix_decay': transition_matrix(False, True, decay = 1.05),\n",
    "    'random_transitison_tensor_decay': transition_tensor(False, False, decay = 1.05),\n",
    "    'random_self_trans_tensor_decay': transition_tensor(False, True, decay = 1.05),\n",
    "    \n",
    "     'random_pattern_matching_decay_5': pattern_matching(5, False, False, decay = 1.001),\n",
    "     'random_self_pattern_matching_decay_5': pattern_matching(5, False, True, decay = 1.001),\n",
    "     'determenistic_pattern_matching_decay_5': pattern_matching(5, True, False, decay = 1.001),\n",
    "     'determenistic_self_pattern_matching_decay_5': pattern_matching(5, True, True, decay = 1.001),\n",
    "    \n",
    "     'random_pattern_matching_decay_6': pattern_matching(6, False, False, decay = 1.001),\n",
    "     'random_self_pattern_matching_decay_6': pattern_matching(6, False, True, decay = 1.001),\n",
    "     'determenistic_pattern_matching_decay_6': pattern_matching(6, True, False, decay = 1.001),\n",
    "     'determenistic_self_pattern_matching_decay_6': pattern_matching(6, True, True, decay = 1.001),\n",
    "}\n",
    "\n",
    "history = []\n",
    "bandit_state = {k:[1,1] for k in agents.keys()}\n",
    "    \n",
    "def multi_armed_bandit_agent (observation, configuration):\n",
    "    \n",
    "    # bandits' params\n",
    "    step_size = 3 \n",
    "    decay_rate = 1.1\n",
    "    \n",
    "    global history, bandit_state\n",
    "    \n",
    "    def log_step(step = None, history = None, agent = None, competitorStep = None, file = 'history.csv'):\n",
    "        if step is None:\n",
    "            step = np.random.randint(3)\n",
    "        if history is None:\n",
    "            history = []\n",
    "        history.append({'step': step, 'competitorStep': competitorStep, 'agent': agent})\n",
    "        if file is not None:\n",
    "            pd.DataFrame(history).to_csv(file, index = False)\n",
    "        return step\n",
    "    \n",
    "    def update_competitor_step(history, competitorStep):\n",
    "        history[-1]['competitorStep'] = int(competitorStep)\n",
    "        return history\n",
    "    \n",
    "    if observation.step == 0:\n",
    "        pass\n",
    "    else:\n",
    "        history = update_competitor_step(history, observation.lastOpponentAction)\n",
    "        \n",
    "        for name, agent in agents.items():\n",
    "            agent_step = agent.step(history[:-1])\n",
    "            bandit_state[name][1] = (bandit_state[name][1] - 1) / decay_rate + 1\n",
    "            bandit_state[name][0] = (bandit_state[name][0] - 1) / decay_rate + 1\n",
    "            \n",
    "            if (history[-1]['competitorStep'] - agent_step) % 3 == 1:\n",
    "                bandit_state[name][1] += step_size\n",
    "            elif (history[-1]['competitorStep'] - agent_step) % 3 == 2:\n",
    "                bandit_state[name][0] += step_size\n",
    "            else:\n",
    "                bandit_state[name][0] += step_size/2\n",
    "                bandit_state[name][1] += step_size/2\n",
    "            \n",
    "    with open('bandit.json', 'w') as outfile:\n",
    "        json.dump(bandit_state, outfile)\n",
    "    \n",
    "    best_proba = -1\n",
    "    best_agent = None\n",
    "    \n",
    "    factor = 0.2  ##### set factor value\n",
    "    \n",
    "    for k in bandit_state.keys():\n",
    "        proba = np.random.beta(factor*bandit_state[k][0],factor*bandit_state[k][1])    ##### set factor\n",
    "        if proba > best_proba:\n",
    "            best_proba = proba\n",
    "            best_agent = k\n",
    "        \n",
    "    step = agents[best_agent].step(history)\n",
    "    \n",
    "    return log_step(step, history, best_agent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
